{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Farm Detection using Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "/home/ubuntu/nbs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: no CUDA-capable device is detected)\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu0 is not available  (error: Unable to get the number of gpus available: no CUDA-capable device is detected)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%cd\n",
    "%cd nbs\n",
    "%matplotlib inline\n",
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu0')\n",
    "\n",
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=180)\n",
    "from shutil import copyfile, copy, rmtree, move\n",
    "\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the set of output folders that we will train our classifier on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "/home/ubuntu/nbs/data/statefarm\n",
      "/home/ubuntu/nbs/data/statefarm/valid\n"
     ]
    }
   ],
   "source": [
    "%cd\n",
    "%cd nbs/data/statefarm\n",
    "%mkdir valid\n",
    "%cd valid\n",
    "%mkdir c0 c1 c2 c3 c4 c5 c6 c7 c8 c9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "/home/ubuntu/nbs/data/statefarm\n",
      "2267\r\n"
     ]
    }
   ],
   "source": [
    "%cd\n",
    "%cd nbs/data/statefarm\n",
    "%ls train/c1 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    g = glob('train/c'+ str(i) + '/*')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for j in range(0,200): copy(shuf[j], 'valid/c' + str(i) + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\r\n"
     ]
    }
   ],
   "source": [
    "%ls valid/c9 | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've setup the folders and directories for our images, we can start setting up our training, validation, and testing sets to feed into our neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "/home/ubuntu/nbs/data/statefarm\n",
      "Found 22424 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "%cd\n",
    "%cd nbs/data/statefarm\n",
    "batch_size = 64\n",
    "batches = get_batches('train', batch_size = batch_size)\n",
    "val_batches = get_batches('valid', batch_size = batch_size * 2)\n",
    "test_batches = get_batches('test', batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "/home/ubuntu/nbs/data\n",
      "Found 22424 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "%cd\n",
    "%cd nbs/data\n",
    "(val_classes, trn_classes, val_labels, trn_labels, val_filenames, filenames, test_filenames) = get_classes('statefarm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_src = \"test/\"\n",
    "dir_dst = \"test/unknown\"\n",
    "\n",
    "for filename in os.listdir(dir_src):\n",
    "    if filename.endswith('.jpg'):\n",
    "        move(dir_src + filename, dir_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/data/statefarm\n",
      "79726\n"
     ]
    }
   ],
   "source": [
    "%cd statefarm\n",
    "%ls testtest | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv3(batches):\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis = 1, input_shape = (3, 224, 224)),\n",
    "        Convolution2D(32, 3, 3, activation = 'relu'),\n",
    "        BatchNormalization(axis = 1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64, 3, 3, activation = 'relu'),\n",
    "        BatchNormalization(axis = 1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(128, 3, 3, activation= 'relu'),\n",
    "        BatchNormalization(axis = 1),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(100, activation = 'relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(100, activation = 'relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(.5),\n",
    "        Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(Adam(lr = .001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch = 1, validation_data = val_batches, \n",
    "                       nb_val_samples = val_batches.nb_sample)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "batches = get_batches('train', gen_t, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 6400/22424 [=======>......................] - ETA: 3538s - loss: 1.4671 - acc: 0.5470"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ebbc8401f9d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-4dfd2e688c5c>\u001b[0m in \u001b[0;36mconv3\u001b[0;34m(batches)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     model.fit_generator(batches, batches.nb_sample, nb_epoch = 1, validation_data = val_batches, \n\u001b[0;32m---> 24\u001b[0;31m                        nb_val_samples = val_batches.nb_sample)\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1442\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1444\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = conv3(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "22424/22424 [==============================] - 588s - loss: 0.8887 - acc: 0.7032 - val_loss: 0.3821 - val_acc: 0.8880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f664ad9ef50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = .0001\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch = 1, validation_data = val_batches, \n",
    "                    nb_val_samples = val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "22424/22424 [==============================] - 589s - loss: 0.5301 - acc: 0.8284 - val_loss: 0.1925 - val_acc: 0.9395\n",
      "Epoch 2/2\n",
      "22424/22424 [==============================] - 587s - loss: 0.3820 - acc: 0.8789 - val_loss: 0.1383 - val_acc: 0.9640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f664ad9ef10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = .00001\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch = 2, validation_data = val_batches, \n",
    "                    nb_val_samples = val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('models/conv3.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights('models/conv3.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_feat = model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_feat = model.predict_generator(val_batches, val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feat = model.predict_generator(batches, batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array('results/test_feat.dat', test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array('results/val_feat.dat', val_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array('results/train_feat.dat', train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/data/statefarm\n"
     ]
    }
   ],
   "source": [
    "%cd ~/nbs/data/statefarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_feat = load_array('results/test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_feat = load_array('results/val_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feat = load_array('results/train_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79726, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22424, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vgg16 Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a pretrained vgg model for its convolutional layers, and then setting up our own dense network to train more specifically on the statefarm driver images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "model = vgg.model\n",
    "last_conv_idx = [i for i,l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches('train', batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "/home/ubuntu/nbs/data\n",
      "Found 22424 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "%cd\n",
    "%cd nbs/data/\n",
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes('statefarm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_feat = conv_model.predict_generator(batches, batches.nb_sample)\n",
    "conv_val_feat = conv_model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "conv_test_feat = conv_model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array('results/conv_val_feat.dat', conv_val_feat)\n",
    "save_array('results/conv_test_feat.dat', conv_test_feat)\n",
    "save_array('results/conv_feat.dat', conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/data/statefarm\n"
     ]
    }
   ],
   "source": [
    "%cd ~/nbs/data/statefarm\n",
    "conv_val_feat = load_array('results/conv_val_feat.dat')\n",
    "#conv_test_feat = load_array('results/conv_test_feat.dat')\n",
    "conv_feat = load_array('results/conv_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22424, 512, 14, 14)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_val_feat.shape\n",
    "#conv_test_feat.shape\n",
    "conv_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vggmodel(p):\n",
    "    model = Sequential([\n",
    "            MaxPooling2D(input_shape = conv_layers[-1].output_shape[1:]),\n",
    "            Flatten(),\n",
    "            Dropout(p/2),\n",
    "            Dense(128, activation = 'relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(p/2),\n",
    "            Dense(128, activation = 'relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(p),\n",
    "            Dense(10, activation = 'softmax')\n",
    "            ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vggmodel = vggmodel(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks the amount of memory our data is using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv_data_feat', 45005865104),\n",
       " ('conv_feat', 9001173136),\n",
       " ('Activation', 904),\n",
       " ('Adam', 904),\n",
       " ('AtrousConv1D', 904),\n",
       " ('AtrousConv2D', 904),\n",
       " ('AtrousConvolution1D', 904),\n",
       " ('AtrousConvolution2D', 904),\n",
       " ('AveragePooling1D', 904),\n",
       " ('AveragePooling2D', 904),\n",
       " ('AveragePooling3D', 904),\n",
       " ('BatchNormalization', 904),\n",
       " ('Bidirectional', 904),\n",
       " ('Conv1D', 904),\n",
       " ('Conv2D', 904),\n",
       " ('Conv3D', 904),\n",
       " ('Convolution1D', 904),\n",
       " ('Convolution2D', 904),\n",
       " ('Convolution3D', 904),\n",
       " ('Cropping1D', 904),\n",
       " ('Cropping2D', 904),\n",
       " ('Cropping3D', 904),\n",
       " ('Deconv2D', 904),\n",
       " ('Deconvolution2D', 904),\n",
       " ('Dense', 904),\n",
       " ('Dropout', 904),\n",
       " ('Embedding', 904),\n",
       " ('FileLink', 904),\n",
       " ('Flatten', 904),\n",
       " ('GRU', 904),\n",
       " ('GlobalAveragePooling2D', 904),\n",
       " ('InputSpec', 904),\n",
       " ('LSTM', 904),\n",
       " ('Lambda', 904),\n",
       " ('Layer', 904),\n",
       " ('MaxPooling1D', 904),\n",
       " ('MaxPooling2D', 904),\n",
       " ('MaxPooling3D', 904),\n",
       " ('MixIterator', 904),\n",
       " ('Model', 904),\n",
       " ('OneHotEncoder', 904),\n",
       " ('OrderedDict', 904),\n",
       " ('RMSprop', 904),\n",
       " ('Reshape', 904),\n",
       " ('SGD', 904),\n",
       " ('SeparableConv2D', 904),\n",
       " ('SeparableConvolution2D', 904),\n",
       " ('Sequential', 904),\n",
       " ('SimpleRNN', 904),\n",
       " ('TSNE', 904),\n",
       " ('TimeDistributed', 904),\n",
       " ('Tokenizer', 904),\n",
       " ('UpSampling1D', 904),\n",
       " ('UpSampling2D', 904),\n",
       " ('UpSampling3D', 904),\n",
       " ('ZeroPadding1D', 904),\n",
       " ('ZeroPadding2D', 904),\n",
       " ('ZeroPadding3D', 904),\n",
       " ('attrgetter', 872),\n",
       " ('chain', 872),\n",
       " ('itemgetter', 872),\n",
       " ('methodcaller', 872),\n",
       " ('conv_layers', 320),\n",
       " ('vgg_mean', 128),\n",
       " ('Input', 120),\n",
       " ('activity_l1', 120),\n",
       " ('activity_l2', 120),\n",
       " ('adjust_dropout', 120),\n",
       " ('categorical_accuracy', 120),\n",
       " ('categorical_crossentropy', 120),\n",
       " ('ceil', 120),\n",
       " ('confusion_matrix', 120),\n",
       " ('conv2d', 120),\n",
       " ('conv_input_length', 120),\n",
       " ('conv_output_length', 120),\n",
       " ('copy_layer', 120),\n",
       " ('copy_layers', 120),\n",
       " ('copy_model', 120),\n",
       " ('copy_weights', 120),\n",
       " ('copyfile', 120),\n",
       " ('do_clip', 120),\n",
       " ('floor', 120),\n",
       " ('get_batches', 120),\n",
       " ('get_classes', 120),\n",
       " ('get_data', 120),\n",
       " ('get_file', 120),\n",
       " ('gray', 120),\n",
       " ('imread', 120),\n",
       " ('insert_layer', 120),\n",
       " ('l1', 120),\n",
       " ('l2', 120),\n",
       " ('layer_from_config', 120),\n",
       " ('load_array', 120),\n",
       " ('merge', 120),\n",
       " ('mk_size', 120),\n",
       " ('mk_square', 120),\n",
       " ('move', 120),\n",
       " ('onehot', 120),\n",
       " ('plot', 120),\n",
       " ('plot_confusion_matrix', 120),\n",
       " ('plots', 120),\n",
       " ('rmtree', 120),\n",
       " ('save_array', 120),\n",
       " ('shared', 120),\n",
       " ('split_at', 120),\n",
       " ('to_bw', 120),\n",
       " ('to_categorical', 120),\n",
       " ('to_plot', 120),\n",
       " ('vgg_ft', 120),\n",
       " ('vgg_ft_bn', 120),\n",
       " ('vgg_preprocess', 120),\n",
       " ('wrap_config', 120),\n",
       " ('zoom', 120),\n",
       " ('Vgg16', 104),\n",
       " ('Vgg16BN', 104),\n",
       " ('absolute_import', 72),\n",
       " ('choice', 72),\n",
       " ('division', 72),\n",
       " ('normal', 72),\n",
       " ('permutation', 72),\n",
       " ('print_function', 72),\n",
       " ('randn', 72),\n",
       " ('uniform', 72),\n",
       " ('vgg', 72),\n",
       " ('l', 64),\n",
       " ('model', 64),\n",
       " ('Image', 56),\n",
       " ('K', 56),\n",
       " ('T', 56),\n",
       " ('activations', 56),\n",
       " ('constraints', 56),\n",
       " ('cuda', 56),\n",
       " ('image', 56),\n",
       " ('initializations', 56),\n",
       " ('misc', 56),\n",
       " ('ndimage', 56),\n",
       " ('nnet', 56),\n",
       " ('np', 56),\n",
       " ('np_utils', 56),\n",
       " ('pd', 56),\n",
       " ('plt', 56),\n",
       " ('pool', 56),\n",
       " ('regularizers', 56),\n",
       " ('sequence', 56),\n",
       " ('i', 24),\n",
       " ('last_conv_idx', 24),\n",
       " ('newaxis', 16)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vggmodel.compile(Adam(lr = .00001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22424 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "22424/22424 [==============================] - 8s - loss: 2.6980 - acc: 0.0961 - val_loss: 2.6128 - val_acc: 0.1030\n",
      "Epoch 2/3\n",
      "22424/22424 [==============================] - 8s - loss: 2.4212 - acc: 0.1239 - val_loss: 2.5030 - val_acc: 0.1085\n",
      "Epoch 3/3\n",
      "22424/22424 [==============================] - 8s - loss: 2.3212 - acc: 0.1490 - val_loss: 2.4712 - val_acc: 0.1030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb20e4a38d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggmodel.fit(conv_feat, trn_labels, batch_size = 64, nb_epoch = 3, validation_data = (conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 512, 7, 7)     0           maxpooling2d_input_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 25088)         0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 25088)         0           flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 128)           3211392     dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNormal(None, 128)           256         dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 128)           0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 128)           16512       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNormal(None, 128)           256         dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 128)           0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 10)            1290        dropout_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3229706\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vggmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22424/22424 [==============================] - 8s - loss: 0.5164 - acc: 0.9172     \n",
      "Epoch 2/5\n",
      "22424/22424 [==============================] - 8s - loss: 0.4886 - acc: 0.9240     \n",
      "Epoch 3/5\n",
      "22424/22424 [==============================] - 8s - loss: 0.4586 - acc: 0.9304     \n",
      "Epoch 4/5\n",
      "22424/22424 [==============================] - 8s - loss: 0.4341 - acc: 0.9374     \n",
      "Epoch 5/5\n",
      "22424/22424 [==============================] - 8s - loss: 0.4115 - acc: 0.9426     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb47f208610>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggmodel.optimizer.lr = .1\n",
    "vggmodel.fit(conv_feat, trn_labels, batch_size = 64, nb_epoch = 5)#, validation_data = (conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/data/statefarm\n"
     ]
    }
   ],
   "source": [
    "%cd ~/nbs/data/statefarm/\n",
    "vggmodel.save_weights('models/vggmodel1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vggmodel.load_weights('models/vggmodel1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation with our Vgg model. Now we have to recreate extra sets of training data, and also add an equivalent amount of training labels for their respective data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/data/statefarm\n"
     ]
    }
   ],
   "source": [
    "%cd ~/nbs/data/statefarm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "vgg_data =  image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "batches_data = get_batches('train/', vgg_data, batch_size= 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_data_feat = conv_model.predict_generator(batches_data, batches_data.nb_sample * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array('results/conv_data_feat.dat', conv_data_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_data_feat = load_array('results/conv_data_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fd97f811df38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv_data_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv_data_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_feat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conv_data_feat = np.concatenate([conv_data_feat, conv_feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I was going to go through a vgg model while using data augmentation on some of our validation data. However our system ran out of memory with all of the necessary components we need to have. So unfortunately I could not run the rest of the models due to lack of memory space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_data_labels = np.concatenate([trn_labels] * 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a separate model that depicts this new data augmentation batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vggdatamodel(p):\n",
    "    model = Sequential([\n",
    "            MaxPooling2D(input_shape = conv_layers[-1].output_shape[1:]),\n",
    "            Flatten(),\n",
    "            Dropout(p/4),\n",
    "            Dense(128, activation = 'relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(p/2),\n",
    "            Dense(64, activation = 'relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(p/4),\n",
    "            Dense(10, activation = 'softmax')\n",
    "            ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vggdatamodel = vggdatamodel(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vggdatamodel.compile(Adam(0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "vggdatamodel.fit(conv_data_feat, trn_data_labels, batch_size = batch_size, nb_epoch = 1, validation_data = (conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vggdatamodel.optimizer.lr = 0.001\n",
    "vggdatamodel.fit(conv_data_feat, trn_data_labels, batch_size = batch_size, nb_epoch = 1, validation_data = (conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vggdatamodel.save_weights('models/vggdatamodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo Labeling some more training data to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part also suffers from lack of memory, in which I could not successfully transfer all of the data for the training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_pseudo = vggmodel.predict(conv_val_feat, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array('results/val_pseudo.dat', val_pseudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comb_pseudo = np.concatenate([trn_labels, val_pseudo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_feat = np.concatenate([conv_feat, conv_val_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vggmodel.compile(Adam(lr = 0.000001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "12224/24424 [==============>...............] - ETA: 18s - loss: 5.0548 - acc: 0.1441"
     ]
    }
   ],
   "source": [
    "vggmodel.fit(comb_feat, comb_pseudo, nb_epoch = 3, batch_size = 64)#, validation_data = (conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vggmodel.optimizer.lr = 0.0001\n",
    "vggmodel.fit(comb_feat, comb_pseudo, nb_epoch = 1, batch_size = 64)#, validation_data = (conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vggmodel.save_weights('results/modelpseudo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Submission Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c = bcolz.carray(arr, rootdir = fname, mode = 'w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "/home/ubuntu/nbs/data/statefarm\n"
     ]
    }
   ],
   "source": [
    "%cd\n",
    "%cd nbs/data/statefarm/\n",
    "test_pred_other = load_array('results/test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_other = np.clip(test_pred_other, .07/9, .93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_name = 'results/subm.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = sorted(batches.class_indices, key = batches.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_81601.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_14887.jpg</td>\n",
       "      <td>0.299819</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.085893</td>\n",
       "      <td>0.063129</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.421190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_62885.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.019743</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.885040</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.046638</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_45125.jpg</td>\n",
       "      <td>0.584869</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.232616</td>\n",
       "      <td>0.136160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_22633.jpg</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.045070</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             img        c0        c1        c2        c3        c4        c5  \\\n",
       "0  img_81601.jpg  0.007778  0.930000  0.007778  0.007778  0.007778  0.007778   \n",
       "1  img_14887.jpg  0.299819  0.007778  0.007778  0.085893  0.063129  0.007778   \n",
       "2  img_62885.jpg  0.007778  0.007778  0.045387  0.007778  0.019743  0.007778   \n",
       "3  img_45125.jpg  0.584869  0.007778  0.007778  0.007778  0.007778  0.007778   \n",
       "4  img_22633.jpg  0.930000  0.007778  0.007778  0.007778  0.007778  0.007778   \n",
       "\n",
       "         c6        c7        c8        c9  \n",
       "0  0.007778  0.007778  0.007778  0.007778  \n",
       "1  0.007778  0.007778  0.117600  0.421190  \n",
       "2  0.885040  0.007778  0.046638  0.007778  \n",
       "3  0.007778  0.043578  0.232616  0.136160  \n",
       "4  0.007778  0.007778  0.045070  0.007778  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(subm_other, columns = classes)\n",
    "submission.insert(0, 'img', img_filenames)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_81601.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_14887.jpg</td>\n",
       "      <td>0.299819</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.085893</td>\n",
       "      <td>0.063129</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.421190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_62885.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.019743</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.885040</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.046638</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_45125.jpg</td>\n",
       "      <td>0.584869</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.232616</td>\n",
       "      <td>0.136160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_22633.jpg</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.045070</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             img        c0        c1        c2        c3        c4        c5  \\\n",
       "0  img_81601.jpg  0.007778  0.930000  0.007778  0.007778  0.007778  0.007778   \n",
       "1  img_14887.jpg  0.299819  0.007778  0.007778  0.085893  0.063129  0.007778   \n",
       "2  img_62885.jpg  0.007778  0.007778  0.045387  0.007778  0.019743  0.007778   \n",
       "3  img_45125.jpg  0.584869  0.007778  0.007778  0.007778  0.007778  0.007778   \n",
       "4  img_22633.jpg  0.930000  0.007778  0.007778  0.007778  0.007778  0.007778   \n",
       "\n",
       "         c6        c7        c8        c9  \n",
       "0  0.007778  0.007778  0.007778  0.007778  \n",
       "1  0.007778  0.007778  0.117600  0.421190  \n",
       "2  0.885040  0.007778  0.046638  0.007778  \n",
       "3  0.007778  0.043578  0.232616  0.136160  \n",
       "4  0.007778  0.007778  0.045070  0.007778  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             img        c0        c1        c2        c3        c4        c5  \\\n",
      "0  img_81601.jpg  0.007778  0.930000  0.007778  0.007778  0.007778  0.007778   \n",
      "1  img_14887.jpg  0.299819  0.007778  0.007778  0.085893  0.063129  0.007778   \n",
      "2  img_62885.jpg  0.007778  0.007778  0.045387  0.007778  0.019743  0.007778   \n",
      "\n",
      "         c6        c7        c8        c9  \n",
      "0  0.007778  0.007778  0.007778  0.007778  \n",
      "1  0.007778  0.007778  0.117600  0.421190  \n",
      "2  0.885040  0.007778  0.046638  0.007778  \n"
     ]
    }
   ],
   "source": [
    "print(submission[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Mismatch between array dtype ('object') and format specifier ('%.6f%.6f%.6f%.6f%.6f%.6f%.6f%.6f%.6f%.6f%.6f')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-b93a87a496a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/test_submission'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%.6f'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                     raise TypeError(\"Mismatch between array dtype ('%s') and \"\n\u001b[1;32m   1161\u001b[0m                                     \u001b[0;34m\"format specifier ('%s')\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m                                     % (str(X.dtype), format))\n\u001b[0m\u001b[1;32m   1163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfooter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0mfooter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfooter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Mismatch between array dtype ('object') and format specifier ('%.6f%.6f%.6f%.6f%.6f%.6f%.6f%.6f%.6f%.6f%.6f')"
     ]
    }
   ],
   "source": [
    "np.savetxt('results/test_submission', submission, fmt = '%.6f' * 11, header = '', comments = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='results/subm.gz' target='_blank'>results/subm.gz</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/nbs/data/statefarm/results/subm.gz"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Submission Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, max): return np.clip(arr, (1 - max)/9, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "/home/ubuntu/nbs/data/statefarm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d5026a573046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'cd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'cd nbs/data/statefarm/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/test_feat.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "%cd \n",
    "%cd nbs/data/statefarm/\n",
    "test_feat = load_array('results/test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = np.clip(test_feat, .01/9, .99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0078,  0.93  ,  0.0078,  0.0078,  0.0078,  0.0078,  0.0078,  0.0078,  0.0078,  0.0078],\n",
       "       [ 0.2998,  0.0078,  0.0078,  0.0859,  0.0631,  0.0078,  0.0078,  0.0078,  0.1176,  0.4212],\n",
       "       [ 0.0078,  0.0078,  0.0454,  0.0078,  0.0197,  0.0078,  0.885 ,  0.0078,  0.0466,  0.0078],\n",
       "       [ 0.5849,  0.0078,  0.0078,  0.0078,  0.0078,  0.0078,  0.0078,  0.0436,  0.2326,  0.1362],\n",
       "       [ 0.93  ,  0.0078,  0.0078,  0.0078,  0.0078,  0.0078,  0.0078,  0.0078,  0.0451,  0.0078]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unknown/img_81601.jpg',\n",
       " 'unknown/img_14887.jpg',\n",
       " 'unknown/img_62885.jpg',\n",
       " 'unknown/img_45125.jpg',\n",
       " 'unknown/img_22633.jpg']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_classes = img + test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_filenames = [(f[8:]) for f in test_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img_81601.jpg',\n",
       " 'img_14887.jpg',\n",
       " 'img_62885.jpg',\n",
       " 'img_45125.jpg',\n",
       " 'img_22633.jpg']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_filenames = np.array(img_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['img_81601.jpg', 'img_14887.jpg', 'img_62885.jpg', 'img_45125.jpg', 'img_22633.jpg'], \n",
       "      dtype='|S14')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subm = np.column_stack((image_filenames, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm2 = np.column_stack((image_filenames, test_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_subm2 = np.row_stack((test_classes, subm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['img_81601.jpg', '0.00777777796611', '0.930000007153', '0.00777777796611',\n",
       "        '0.00777777796611', '0.00777777796611', '0.00777777796611', '0.00777777796611',\n",
       "        '0.00777777796611', '0.00777777796611', '0.00777777796611'],\n",
       "       ['img_14887.jpg', '0.299818694592', '0.00777777796611', '0.00777777796611',\n",
       "        '0.0858930796385', '0.0631291419268', '0.00777777796611', '0.00777777796611',\n",
       "        '0.00777777796611', '0.117599993944', '0.421190172434'],\n",
       "       ['img_62885.jpg', '0.00777777796611', '0.00777777796611', '0.0453870147467',\n",
       "        '0.00777777796611', '0.0197426471859', '0.00777777796611', '0.885040462017',\n",
       "        '0.00777777796611', '0.0466382727027', '0.00777777796611'],\n",
       "       ['img_45125.jpg', '0.584869027138', '0.00777777796611', '0.00777777796611',\n",
       "        '0.00777777796611', '0.00777777796611', '0.00777777796611', '0.00777777796611',\n",
       "        '0.0435781218112', '0.232615575194', '0.13616040349'],\n",
       "       ['img_22633.jpg', '0.930000007153', '0.00777777796611', '0.00777777796611',\n",
       "        '0.00777777796611', '0.00777777796611', '0.00777777796611', '0.00777777796611',\n",
       "        '0.00777777796611', '0.0450695753098', '0.00777777796611']], \n",
       "      dtype='|S32')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_classes = np.array(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'], \n",
       "      dtype='|S3')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = ['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_subm = np.row_stack((test_classes, subm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'],\n",
       "       ['img_81601.jpg', '0.00111111113802', '0.990000009537', '0.00111111113802',\n",
       "        '0.00111111113802', '0.00111111113802', '0.00111111113802', '0.00111111113802',\n",
       "        '0.00111111113802', '0.00111111113802', '0.00111111113802'],\n",
       "       ['img_14887.jpg', '0.299818694592', '0.00209501828067', '0.00111111113802',\n",
       "        '0.0858930796385', '0.0631291419268', '0.00259108375758', '0.00761960726231',\n",
       "        '0.00111111113802', '0.117599993944', '0.421190172434'],\n",
       "       ['img_62885.jpg', '0.00111111113802', '0.00111111113802', '0.0453870147467',\n",
       "        '0.00111111113802', '0.0197426471859', '0.00111364515033', '0.885040462017',\n",
       "        '0.00111111113802', '0.0466382727027', '0.00116757268552'],\n",
       "       ['img_45125.jpg', '0.584869027138', '0.00111111113802', '0.00111111113802',\n",
       "        '0.00111111113802', '0.00111111113802', '0.00111111113802', '0.00111111113802',\n",
       "        '0.0435781218112', '0.232615575194', '0.13616040349']], \n",
       "      dtype='|S32')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'],\n",
       "       ['img_81601.jpg', '4.08481209888e-05', '0.999704658985', '9.58340297075e-06',\n",
       "        '1.87718032976e-05', '5.32808144271e-07', '2.11346701917e-07', '4.7516565246e-05',\n",
       "        '2.66900224233e-06', '2.06583695217e-06', '0.000173020656803'],\n",
       "       ['img_14887.jpg', '0.299818694592', '0.00209501828067', '4.4994885684e-05',\n",
       "        '0.0858930796385', '0.0631291419268', '0.00259108375758', '0.00761960726231',\n",
       "        '1.82215462701e-05', '0.117599993944', '0.421190172434'],\n",
       "       ['img_62885.jpg', '0.000131585198687', '1.12135458039e-05', '0.0453870147467',\n",
       "        '1.84712334885e-05', '0.0197426471859', '0.00111364515033', '0.885040462017',\n",
       "        '0.000749175960664', '0.0466382727027', '0.00116757268552'],\n",
       "       ['img_45125.jpg', '0.584869027138', '0.000525393290445', '0.000197202665731',\n",
       "        '0.000274943362456', '0.00110527721699', '0.000214307307033', '0.000459816626972',\n",
       "        '0.0435781218112', '0.232615575194', '0.13616040349']], \n",
       "      dtype='|S32')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_subm2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('results/please_subm_againplsagain.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(full_subm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "/home/ubuntu/nbs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Mismatch between array dtype ('|S32') and format specifier ('%.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-fe266b8a234e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m np.savetxt('data/statefarm/results/test_pred5.csv', full_subm, delimiter = ' ',\n\u001b[0;32m----> 5\u001b[0;31m            header = 'img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9', comments = '')\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mFileLink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/statefarm/results/test_pred5.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                     raise TypeError(\"Mismatch between array dtype ('%s') and \"\n\u001b[1;32m   1161\u001b[0m                                     \u001b[0;34m\"format specifier ('%s')\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m                                     % (str(X.dtype), format))\n\u001b[0m\u001b[1;32m   1163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfooter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0mfooter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfooter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Mismatch between array dtype ('|S32') and format specifier ('%.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e %.18e')"
     ]
    }
   ],
   "source": [
    "%cd\n",
    "%cd nbs\n",
    "import bcolz\n",
    "np.savetxt('data/statefarm/results/test_pred5.csv', subm, delimiter = ' ',\n",
    "           header = 'img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9', comments = '')\n",
    "FileLink('data/statefarm/results/test_pred5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_name = 'results/subm.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = sorted(batches.class_indices, key = batches.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>own/img_81601.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>own/img_14887.jpg</td>\n",
       "      <td>0.299819</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.085893</td>\n",
       "      <td>0.063129</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.421190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>own/img_62885.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.019743</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.885040</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.046638</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>own/img_45125.jpg</td>\n",
       "      <td>0.584869</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.232616</td>\n",
       "      <td>0.136160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>own/img_22633.jpg</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.045070</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 img        c0        c1        c2        c3        c4  \\\n",
       "0  own/img_81601.jpg  0.007778  0.930000  0.007778  0.007778  0.007778   \n",
       "1  own/img_14887.jpg  0.299819  0.007778  0.007778  0.085893  0.063129   \n",
       "2  own/img_62885.jpg  0.007778  0.007778  0.045387  0.007778  0.019743   \n",
       "3  own/img_45125.jpg  0.584869  0.007778  0.007778  0.007778  0.007778   \n",
       "4  own/img_22633.jpg  0.930000  0.007778  0.007778  0.007778  0.007778   \n",
       "\n",
       "         c5        c6        c7        c8        c9  \n",
       "0  0.007778  0.007778  0.007778  0.007778  0.007778  \n",
       "1  0.007778  0.007778  0.007778  0.117600  0.421190  \n",
       "2  0.007778  0.885040  0.007778  0.046638  0.007778  \n",
       "3  0.007778  0.007778  0.043578  0.232616  0.136160  \n",
       "4  0.007778  0.007778  0.007778  0.045070  0.007778  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(subm, columns = classes)\n",
    "submission.insert(0, 'img', [a[4:] for a in test_filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False, compression = 'gzip')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
